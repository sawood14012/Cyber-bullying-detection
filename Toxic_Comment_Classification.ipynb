{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic Comment Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.9 64-bit ('env')",
      "metadata": {
        "interpreter": {
          "hash": "19b49fef126041c60f1856132717eba6193fc81801d5aa2165ae4f40a4518494"
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F9JAmfVZEeM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa1c7cb-0d79-469a-ef00-e74af9bf5a5a"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%tensorflow_version` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HFgUsvrZIwv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7L4IAyzbKgw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f19f80f0-7cad-4c9a-8437-5b29e0880312"
      },
      "source": [
        "df = pd.read_csv('Processed CyberBullying file.csv')\n",
        "print(df.shape)\n",
        "\n",
        "#remove null values\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "df.isnull().sum()\n",
        "print(df.columns)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32450, 3)\nIndex(['text', 'tags', 'processed'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO8Cy9X-bh8X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "19fef603-531a-45d7-d752-330e0f45e9e6"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  tags  \\\n",
              "0  so what? \\n\\nwhat should i do? then promise to...     0   \n",
              "1  \"\\n\\nAnd PBS as you are a bit of an expert on ...     0   \n",
              "2  WTF! \\n\\nu fckin faggot ass mutha fcker u jus ...     1   \n",
              "3       Great, I'm glad we managed to work this out.     0   \n",
              "4  \"\\n\\n Hu12 administrator apparent libel and ab...     0   \n",
              "5  Hi! I am back again!\\nLast warning!\\nStop undo...     1   \n",
              "6  you stink \\nYou suck HangingCurve/Blueboy96. E...     1   \n",
              "7  crash rules \\n\\nThe Rules of Wedding Crashing ...     0   \n",
              "8  \"\\nDoes this look good? I changed it as the so...     0   \n",
              "9  Wikipedia:Requests for arbitration/Husnock\\nHe...     0   \n",
              "\n",
              "                                           processed  \n",
              "0  ? ? promise never edit wikipedia get unblocked...  \n",
              "1  `` pbs bit expert wiki-policies know read some...  \n",
              "2  wtf ! u fckin faggot ass mutha fcker u jus re-...  \n",
              "3                     great , 'm glad managed work .  \n",
              "4  `` hu12 administrator apparent libel abuse rep...  \n",
              "5  hi ! back ! last warning ! stop undoing edits ...  \n",
              "6  stink suck hangingcurve/blueboy96 . even admin...  \n",
              "7  crash rules rules wedding crashing created del...  \n",
              "8  `` look good ? changed source talk theme music...  \n",
              "9  wikipedia : requests arbitration/husnock hello...  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>tags</th>\n      <th>processed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>so what? \\n\\nwhat should i do? then promise to...</td>\n      <td>0</td>\n      <td>? ? promise never edit wikipedia get unblocked...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"\\n\\nAnd PBS as you are a bit of an expert on ...</td>\n      <td>0</td>\n      <td>`` pbs bit expert wiki-policies know read some...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>WTF! \\n\\nu fckin faggot ass mutha fcker u jus ...</td>\n      <td>1</td>\n      <td>wtf ! u fckin faggot ass mutha fcker u jus re-...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Great, I'm glad we managed to work this out.</td>\n      <td>0</td>\n      <td>great , 'm glad managed work .</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"\\n\\n Hu12 administrator apparent libel and ab...</td>\n      <td>0</td>\n      <td>`` hu12 administrator apparent libel abuse rep...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Hi! I am back again!\\nLast warning!\\nStop undo...</td>\n      <td>1</td>\n      <td>hi ! back ! last warning ! stop undoing edits ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>you stink \\nYou suck HangingCurve/Blueboy96. E...</td>\n      <td>1</td>\n      <td>stink suck hangingcurve/blueboy96 . even admin...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>crash rules \\n\\nThe Rules of Wedding Crashing ...</td>\n      <td>0</td>\n      <td>crash rules rules wedding crashing created del...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>\"\\nDoes this look good? I changed it as the so...</td>\n      <td>0</td>\n      <td>`` look good ? changed source talk theme music...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Wikipedia:Requests for arbitration/Husnock\\nHe...</td>\n      <td>0</td>\n      <td>wikipedia : requests arbitration/husnock hello...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bXE8JiCbo8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4382e86d-2a3b-49ac-9927-475b0ea4500d"
      },
      "source": [
        "#check GPU Availability\n",
        "import tensorflow as tf\n",
        "tf.test.is_gpu_available()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqdnhKG7byxO"
      },
      "source": [
        "df.describe()\n",
        "\n",
        "# classes = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
        "classes = ['Toxic', 'Not Toxic']\n",
        "# targets = df[classes].values\n",
        "targets = df['tags'].values\n",
        "\n",
        "#perform feature engineering using GloVe Embeddings\n",
        "\n",
        "embedding_file_path = 'glove.6B.100d.txt' #GloVe embedding file. Almost 350MB"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3m9xV5yjs3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ac920d-be46-4dc1-d0b6-d1fce60e1c0d"
      },
      "source": [
        "targets[:12]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58mW40U6dGrD"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.layers import Input, Embedding, GRU, Dense, Activation, Dropout, CuDNNGRU\n",
        "from tensorflow.keras.layers import RNN, concatenate\n",
        "from tensorflow.keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPool1D\n",
        "\n",
        "from tensorflow.keras import initializers, optimizers\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8fFU6Dbe9bc"
      },
      "source": [
        "features = df['text'].fillna(' ').str.lower()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5fMBEZoeJjK"
      },
      "source": [
        "max_features, embed_size, maxlen = 100000, 100, 150\n",
        "tokenizer = Tokenizer(max_features)\n",
        "\n",
        "tokenizer.fit_on_texts(list(features))\n",
        "sentences = tokenizer.texts_to_sequences(features)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gggU4SO9fVz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1015ba35-d091-42fd-e58f-91856801704e"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34, 35, 35, 60, 5, 27, 87, 2928, 3, 188, 88, 17, 28, 6, 5, 41, 71, 2007]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkuZW1Offa4b"
      },
      "source": [
        "padded_features = pad_sequences(sentences, maxlen=maxlen)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQDt4hwXfkoz"
      },
      "source": [
        "def get_coefs(word, *arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "#costly operations, do it at your own risk\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(embedding_file_path))\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))+1\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hjMUcdNLmhv"
      },
      "source": [
        "max_features = nb_words"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9xXwCJZhF3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcbde34f-fd33-460a-8e71-ff04e1dda50d"
      },
      "source": [
        "#build the Deep Learning model\n",
        "\n",
        "orig_input = Input(shape=(maxlen,)) #series\n",
        "embed_layer = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable=False)(orig_input)\n",
        "bi_layer = Bidirectional(GRU(128, return_sequences=True))(embed_layer)\n",
        "avg_pool = GlobalAveragePooling1D()(bi_layer)\n",
        "max_pool = GlobalMaxPool1D()(bi_layer)\n",
        "\n",
        "conc_layer = concatenate([avg_pool, max_pool])\n",
        "prediction_layer = Dense(1, activation='sigmoid')(conc_layer)\n",
        "\n",
        "model = Model(inputs=orig_input, outputs=prediction_layer)\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizers.Adam(clipnorm=1.))\n",
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_3 (InputLayer)            [(None, 150)]        0                                            \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 150, 100)     7029300     input_3[0][0]                    \n__________________________________________________________________________________________________\nbidirectional_2 (Bidirectional) (None, 150, 256)     175872      embedding_2[0][0]                \n__________________________________________________________________________________________________\nglobal_average_pooling1d_2 (Glo (None, 256)          0           bidirectional_2[0][0]            \n__________________________________________________________________________________________________\nglobal_max_pooling1d_2 (GlobalM (None, 256)          0           bidirectional_2[0][0]            \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 512)          0           global_average_pooling1d_2[0][0] \n                                                                 global_max_pooling1d_2[0][0]     \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1)            513         concatenate_2[0][0]              \n==================================================================================================\nTotal params: 7,205,685\nTrainable params: 176,385\nNon-trainable params: 7,029,300\n__________________________________________________________________________________________________\nNone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DupBe_Odiwdm"
      },
      "source": [
        "saved_model_file = 'best_acc_meer_model_weights.hdf5'\n",
        "\n",
        "ckpt = ModelCheckpoint(saved_model_file, monitor='val_acc', save_best_only=True, save_weights_only=True, mode='max')\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh5e1kKkjHYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed25834f-5e22-4261-e15e-22f5b65d5d5a"
      },
      "source": [
        "bs, ep = 32, 10\n",
        "\n",
        "model.fit(padded_features, targets, validation_split=0.3, epochs=ep, batch_size=bs, callbacks=[ckpt])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 22715 samples, validate on 9735 samples\n",
            "Epoch 1/10\n",
            "22715/22715 [==============================] - 194s 9ms/sample - loss: 0.2885 - acc: 0.8753 - val_loss: 0.2405 - val_acc: 0.9004\n",
            "Epoch 2/10\n",
            "22715/22715 [==============================] - 216s 10ms/sample - loss: 0.2225 - acc: 0.9087 - val_loss: 0.2184 - val_acc: 0.9084\n",
            "Epoch 3/10\n",
            "22715/22715 [==============================] - 185s 8ms/sample - loss: 0.1938 - acc: 0.9212 - val_loss: 0.2091 - val_acc: 0.9138\n",
            "Epoch 4/10\n",
            "22715/22715 [==============================] - 186s 8ms/sample - loss: 0.1631 - acc: 0.9353 - val_loss: 0.2124 - val_acc: 0.9118\n",
            "Epoch 5/10\n",
            "22715/22715 [==============================] - 187s 8ms/sample - loss: 0.1332 - acc: 0.9482 - val_loss: 0.2109 - val_acc: 0.9149\n",
            "Epoch 6/10\n",
            "22715/22715 [==============================] - 185s 8ms/sample - loss: 0.1029 - acc: 0.9626 - val_loss: 0.2294 - val_acc: 0.9119\n",
            "Epoch 7/10\n",
            "22715/22715 [==============================] - 179s 8ms/sample - loss: 0.0759 - acc: 0.9747 - val_loss: 0.2582 - val_acc: 0.9118\n",
            "Epoch 8/10\n",
            "22715/22715 [==============================] - 196s 9ms/sample - loss: 0.0514 - acc: 0.9837 - val_loss: 0.2738 - val_acc: 0.9071\n",
            "Epoch 9/10\n",
            "22715/22715 [==============================] - 188s 8ms/sample - loss: 0.0403 - acc: 0.9882 - val_loss: 0.2850 - val_acc: 0.9118\n",
            "Epoch 10/10\n",
            "22715/22715 [==============================] - 172s 8ms/sample - loss: 0.0228 - acc: 0.9947 - val_loss: 0.3605 - val_acc: 0.9031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x131c75090>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L6XSbzwjYYu"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('tokenizer.pickle','wb') as f:\n",
        "    pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#save tokenizer to fit on texts during testing."
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLMFwZCflWqX"
      },
      "source": [
        "#save embedding matrix, model\n",
        "with open('embedding_matrix.pickle', 'wb') as f:\n",
        "    pickle.dump(embedding_matrix,f,protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "model.save('Toxic_Comments_Model.model')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLwUNksPl5ue"
      },
      "source": [
        "#call a testing / prediction line.\n",
        "\n",
        "def get_coefs(word, *arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "def test_prediction(sent, tokenizer='tokenizer.pickle', model='Toxic_Comments_Model.model'):\n",
        "\n",
        "    \n",
        "    if len(sent) == 0:\n",
        "        print(\"No input entered - please enter a valid input\")\n",
        "        return\n",
        "        \n",
        "    import numpy as np\n",
        "    import nltk\n",
        "    import os\n",
        "\n",
        "    import pickle\n",
        "\n",
        "    from tensorflow.keras.models import Model\n",
        "    #from tensorflow.keras.optimizers import Adam\n",
        "    from tensorflow.keras.models import load_model\n",
        "    from tensorflow.keras.models import model_from_json\n",
        "    from tensorflow.keras import optimizers\n",
        "\n",
        "    from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "    #do all the preprocessing you did earlier\n",
        "\n",
        "    max_features, embed_size, maxlen = 100000, 100, 150\n",
        "\n",
        "    tokenizer_file = open(tokenizer,'rb')\n",
        "    tokenizer = pickle.load(tokenizer_file)\n",
        "    tokenizer_file.close()\n",
        "\n",
        "    features = sent.lower()\n",
        "\n",
        "    sentences = tokenizer.texts_to_sequences([features])\n",
        "\n",
        "    padded_features = pad_sequences(sentences, maxlen=maxlen) #features\n",
        "\n",
        "    json_file = open('model.json', 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    loaded_model.load_weights(\"best_acc_meer_model_weights.hdf5\")\n",
        "    loaded_model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizers.Adam(clipnorm=1.))\n",
        "    print(\"Loaded model from disk\")\n",
        "\n",
        "    #model = load_model('Toxic_Comments_Model.model') #load the trained model\n",
        "    #model.predict()\n",
        "\n",
        "    label_list = loaded_model.predict(padded_features)\n",
        "    print(label_list)\n",
        "\n",
        "    # predict_labels = []\n",
        "    # for item in label_list[0]:\n",
        "        # predict_labels.append(int(round(item)))\n",
        "    \n",
        "    # classes = [\"Toxic\",\", Severely Toxic\",\", Obscene\",\", a Threat\",\", an Insult\",\", Identity Hate\"]\n",
        "    classes = ['Not Toxic', 'Toxic']\n",
        "\n",
        "    print(\"The sentence : '{}', is classified as : \\n\".format(sent))\n",
        "    returned_class = classes[1] if label_list[0][0]>=0.5 else classes[0]\n",
        "    # print(returned_class)\n",
        "\n",
        "    \"\"\"\n",
        "    for i in range(len(classes)):\n",
        "        if predict_labels[i] == 1:\n",
        "            print(classes[i],end=\" \")\n",
        "    \"\"\"\n",
        "    proba = 1-label_list[0][0] if label_list[0][0] < 0.5 else label_list[0][0] \n",
        "    return proba, returned_class\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XxT1RLeOPXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa35e1b-97e6-4329-fe77-8890c43cf436"
      },
      "source": [
        "proba, label = test_prediction('I am hungry, you bitch. My hatred for you knows no bounds')\n",
        "print('PROBABILITY : {} | LABEL : {}'.format(proba, label))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /Users/sawood/cyber_bullying/env/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loaded model from disk\n",
            "[[0.9911705]]\n",
            "The sentence : 'I am hungry, you bitch. My hatred for you knows no bounds', is classified as : \n",
            "\n",
            "PROBABILITY : 0.9911705255508423 | LABEL : Toxic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT4YXuRBQhYP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0763a03a-87e3-41f5-c079-c205bc95e5d6"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Package                  Version        \n",
            "------------------------ ---------------\n",
            "absl-py                  0.9.0          \n",
            "alabaster                0.7.12         \n",
            "albumentations           0.1.12         \n",
            "altair                   4.1.0          \n",
            "asgiref                  3.2.7          \n",
            "astor                    0.8.1          \n",
            "astropy                  4.0.1.post1    \n",
            "astunparse               1.6.3          \n",
            "atari-py                 0.2.6          \n",
            "atomicwrites             1.3.0          \n",
            "attrs                    19.3.0         \n",
            "audioread                2.1.8          \n",
            "autograd                 1.3            \n",
            "Babel                    2.8.0          \n",
            "backcall                 0.1.0          \n",
            "backports.tempfile       1.0            \n",
            "backports.weakref        1.0.post1      \n",
            "beautifulsoup4           4.6.3          \n",
            "bleach                   3.1.4          \n",
            "blis                     0.4.1          \n",
            "bokeh                    1.4.0          \n",
            "boto                     2.49.0         \n",
            "boto3                    1.12.43        \n",
            "botocore                 1.15.43        \n",
            "Bottleneck               1.3.2          \n",
            "branca                   0.4.0          \n",
            "bs4                      0.0.1          \n",
            "bz2file                  0.98           \n",
            "CacheControl             0.12.6         \n",
            "cachetools               3.1.1          \n",
            "catalogue                1.0.0          \n",
            "certifi                  2020.4.5.1     \n",
            "cffi                     1.14.0         \n",
            "chainer                  6.5.0          \n",
            "chardet                  3.0.4          \n",
            "click                    7.1.1          \n",
            "cloudpickle              1.3.0          \n",
            "cmake                    3.12.0         \n",
            "cmdstanpy                0.4.0          \n",
            "colorlover               0.3.0          \n",
            "community                1.0.0b1        \n",
            "contextlib2              0.5.5          \n",
            "convertdate              2.2.0          \n",
            "coverage                 3.7.1          \n",
            "coveralls                0.5            \n",
            "crcmod                   1.7            \n",
            "cufflinks                0.17.3         \n",
            "cupy-cuda101             6.5.0          \n",
            "cvxopt                   1.2.5          \n",
            "cvxpy                    1.0.31         \n",
            "cycler                   0.10.0         \n",
            "cymem                    2.0.3          \n",
            "Cython                   0.29.16        \n",
            "daft                     0.0.4          \n",
            "dask                     2.12.0         \n",
            "dataclasses              0.7            \n",
            "datascience              0.10.6         \n",
            "decorator                4.4.2          \n",
            "defusedxml               0.6.0          \n",
            "descartes                1.1.0          \n",
            "dill                     0.3.1.1        \n",
            "distributed              1.25.3         \n",
            "Django                   3.0.5          \n",
            "dlib                     19.18.0        \n",
            "dm-sonnet                1.35           \n",
            "docopt                   0.6.2          \n",
            "docutils                 0.15.2         \n",
            "dopamine-rl              1.0.5          \n",
            "earthengine-api          0.1.218        \n",
            "easydict                 1.9            \n",
            "ecos                     2.0.7.post1    \n",
            "editdistance             0.5.3          \n",
            "en-core-web-sm           2.2.5          \n",
            "entrypoints              0.3            \n",
            "ephem                    3.7.7.1        \n",
            "et-xmlfile               1.0.1          \n",
            "fa2                      0.3.5          \n",
            "fancyimpute              0.4.3          \n",
            "fastai                   1.0.60         \n",
            "fastdtw                  0.3.4          \n",
            "fastprogress             0.2.3          \n",
            "fastrlock                0.4            \n",
            "fbprophet                0.6            \n",
            "feather-format           0.4.0          \n",
            "featuretools             0.4.1          \n",
            "filelock                 3.0.12         \n",
            "firebase-admin           4.1.0          \n",
            "fix-yahoo-finance        0.0.22         \n",
            "Flask                    1.1.2          \n",
            "folium                   0.8.3          \n",
            "fsspec                   0.7.2          \n",
            "future                   0.16.0         \n",
            "gast                     0.3.3          \n",
            "GDAL                     2.2.2          \n",
            "gdown                    3.6.4          \n",
            "gensim                   3.6.0          \n",
            "geographiclib            1.50           \n",
            "geopy                    1.17.0         \n",
            "gevent                   1.4.0          \n",
            "gin-config               0.3.0          \n",
            "glob2                    0.7            \n",
            "google                   2.0.3          \n",
            "google-api-core          1.16.0         \n",
            "google-api-python-client 1.7.12         \n",
            "google-auth              1.7.2          \n",
            "google-auth-httplib2     0.0.3          \n",
            "google-auth-oauthlib     0.4.1          \n",
            "google-cloud-bigquery    1.21.0         \n",
            "google-cloud-core        1.0.3          \n",
            "google-cloud-datastore   1.8.0          \n",
            "google-cloud-firestore   1.6.2          \n",
            "google-cloud-language    1.2.0          \n",
            "google-cloud-storage     1.18.1         \n",
            "google-cloud-translate   1.5.0          \n",
            "google-colab             1.0.0          \n",
            "google-pasta             0.2.0          \n",
            "google-resumable-media   0.4.1          \n",
            "googleapis-common-protos 1.51.0         \n",
            "googledrivedownloader    0.4            \n",
            "graph-nets               1.0.5          \n",
            "graphviz                 0.10.1         \n",
            "greenlet                 0.4.15         \n",
            "grpcio                   1.28.1         \n",
            "gspread                  3.0.1          \n",
            "gspread-dataframe        3.0.6          \n",
            "gunicorn                 20.0.4         \n",
            "gym                      0.17.1         \n",
            "h5py                     2.10.0         \n",
            "HeapDict                 1.0.1          \n",
            "holidays                 0.9.12         \n",
            "html5lib                 1.0.1          \n",
            "httpimport               0.5.18         \n",
            "httplib2                 0.17.3         \n",
            "httplib2shim             0.0.3          \n",
            "humanize                 0.5.1          \n",
            "hyperopt                 0.1.2          \n",
            "ideep4py                 2.0.0.post3    \n",
            "idna                     2.8            \n",
            "image                    1.5.31         \n",
            "imageio                  2.4.1          \n",
            "imagesize                1.2.0          \n",
            "imbalanced-learn         0.4.3          \n",
            "imblearn                 0.0            \n",
            "imgaug                   0.2.9          \n",
            "importlib-metadata       1.6.0          \n",
            "imutils                  0.5.3          \n",
            "inflect                  2.1.0          \n",
            "intel-openmp             2020.0.133     \n",
            "intervaltree             2.1.0          \n",
            "ipykernel                4.10.1         \n",
            "ipython                  5.5.0          \n",
            "ipython-genutils         0.2.0          \n",
            "ipython-sql              0.3.9          \n",
            "ipywidgets               7.5.1          \n",
            "itsdangerous             1.1.0          \n",
            "jax                      0.1.62         \n",
            "jaxlib                   0.1.42         \n",
            "jdcal                    1.4.1          \n",
            "jedi                     0.17.0         \n",
            "jieba                    0.42.1         \n",
            "Jinja2                   2.11.2         \n",
            "jmespath                 0.9.5          \n",
            "joblib                   0.14.1         \n",
            "jpeg4py                  0.1.4          \n",
            "jsonschema               2.6.0          \n",
            "jupyter                  1.0.0          \n",
            "jupyter-client           5.3.4          \n",
            "jupyter-console          5.2.0          \n",
            "jupyter-core             4.6.3          \n",
            "kaggle                   1.5.6          \n",
            "kapre                    0.1.3.1        \n",
            "Keras                    2.3.1          \n",
            "Keras-Applications       1.0.8          \n",
            "Keras-Preprocessing      1.1.0          \n",
            "keras-vis                0.4.1          \n",
            "kfac                     0.2.0          \n",
            "kiwisolver               1.2.0          \n",
            "knnimpute                0.1.0          \n",
            "librosa                  0.6.3          \n",
            "lightgbm                 2.2.3          \n",
            "llvmlite                 0.31.0         \n",
            "lmdb                     0.98           \n",
            "lucid                    0.3.8          \n",
            "LunarCalendar            0.0.9          \n",
            "lxml                     4.2.6          \n",
            "magenta                  0.3.19         \n",
            "Markdown                 3.2.1          \n",
            "MarkupSafe               1.1.1          \n",
            "matplotlib               3.2.1          \n",
            "matplotlib-venn          0.11.5         \n",
            "mesh-tensorflow          0.1.12         \n",
            "mido                     1.2.6          \n",
            "mir-eval                 0.5            \n",
            "missingno                0.4.2          \n",
            "mistune                  0.8.4          \n",
            "mizani                   0.6.0          \n",
            "mkl                      2019.0         \n",
            "mlxtend                  0.14.0         \n",
            "more-itertools           8.2.0          \n",
            "moviepy                  0.2.3.5        \n",
            "mpi4py                   3.0.3          \n",
            "mpmath                   1.1.0          \n",
            "msgpack                  1.0.0          \n",
            "multiprocess             0.70.9         \n",
            "multitasking             0.0.9          \n",
            "murmurhash               1.0.2          \n",
            "music21                  5.5.0          \n",
            "natsort                  5.5.0          \n",
            "nbconvert                5.6.1          \n",
            "nbformat                 5.0.6          \n",
            "networkx                 2.4            \n",
            "nibabel                  3.0.2          \n",
            "nltk                     3.2.5          \n",
            "notebook                 5.2.2          \n",
            "np-utils                 0.5.12.1       \n",
            "numba                    0.48.0         \n",
            "numexpr                  2.7.1          \n",
            "numpy                    1.18.3         \n",
            "nvidia-ml-py3            7.352.0        \n",
            "oauth2client             4.1.3          \n",
            "oauthlib                 3.1.0          \n",
            "okgrade                  0.4.3          \n",
            "opencv-contrib-python    4.1.2.30       \n",
            "opencv-python            4.1.2.30       \n",
            "openpyxl                 2.5.9          \n",
            "opt-einsum               3.2.1          \n",
            "osqp                     0.6.1          \n",
            "packaging                20.3           \n",
            "palettable               3.3.0          \n",
            "pandas                   1.0.3          \n",
            "pandas-datareader        0.8.1          \n",
            "pandas-gbq               0.11.0         \n",
            "pandas-profiling         1.4.1          \n",
            "pandocfilters            1.4.2          \n",
            "parso                    0.7.0          \n",
            "pathlib                  1.0.1          \n",
            "patsy                    0.5.1          \n",
            "pexpect                  4.8.0          \n",
            "pickleshare              0.7.5          \n",
            "Pillow                   7.0.0          \n",
            "pip                      19.3.1         \n",
            "pip-tools                4.5.1          \n",
            "plac                     1.1.3          \n",
            "plotly                   4.4.1          \n",
            "plotnine                 0.6.0          \n",
            "pluggy                   0.7.1          \n",
            "portpicker               1.3.1          \n",
            "prefetch-generator       1.0.1          \n",
            "preshed                  3.0.2          \n",
            "pretty-midi              0.2.8          \n",
            "prettytable              0.7.2          \n",
            "progressbar2             3.38.0         \n",
            "prometheus-client        0.7.1          \n",
            "promise                  2.3            \n",
            "prompt-toolkit           1.0.18         \n",
            "protobuf                 3.10.0         \n",
            "psutil                   5.4.8          \n",
            "psycopg2                 2.7.6.1        \n",
            "ptvsd                    5.0.0a12       \n",
            "ptyprocess               0.6.0          \n",
            "py                       1.8.1          \n",
            "pyarrow                  0.14.1         \n",
            "pyasn1                   0.4.8          \n",
            "pyasn1-modules           0.2.8          \n",
            "pycocotools              2.0.0          \n",
            "pycparser                2.20           \n",
            "pydata-google-auth       1.0.0          \n",
            "pydot                    1.3.0          \n",
            "pydot-ng                 2.0.0          \n",
            "pydotplus                2.0.2          \n",
            "PyDrive                  1.3.1          \n",
            "pyemd                    0.5.1          \n",
            "pyglet                   1.5.0          \n",
            "Pygments                 2.1.3          \n",
            "pygobject                3.26.1         \n",
            "pymc3                    3.7            \n",
            "PyMeeus                  0.3.7          \n",
            "pymongo                  3.10.1         \n",
            "pymystem3                0.2.0          \n",
            "PyOpenGL                 3.1.5          \n",
            "pyparsing                2.4.7          \n",
            "pypng                    0.0.20         \n",
            "pyrsistent               0.16.0         \n",
            "pysndfile                1.3.8          \n",
            "PySocks                  1.7.1          \n",
            "pystan                   2.19.1.1       \n",
            "pytest                   3.6.4          \n",
            "python-apt               1.6.5+ubuntu0.2\n",
            "python-chess             0.23.11        \n",
            "python-dateutil          2.8.1          \n",
            "python-louvain           0.14           \n",
            "python-rtmidi            1.4.0          \n",
            "python-slugify           4.0.0          \n",
            "python-utils             2.4.0          \n",
            "pytz                     2018.9         \n",
            "PyWavelets               1.1.1          \n",
            "PyYAML                   3.13           \n",
            "pyzmq                    19.0.0         \n",
            "qtconsole                4.7.3          \n",
            "QtPy                     1.9.0          \n",
            "regex                    2019.12.20     \n",
            "requests                 2.21.0         \n",
            "requests-oauthlib        1.3.0          \n",
            "resampy                  0.2.2          \n",
            "retrying                 1.3.3          \n",
            "rpy2                     3.2.7          \n",
            "rsa                      4.0            \n",
            "s3fs                     0.4.2          \n",
            "s3transfer               0.3.3          \n",
            "scikit-image             0.16.2         \n",
            "scikit-learn             0.22.2.post1   \n",
            "scipy                    1.4.1          \n",
            "screen-resolution-extra  0.0.0          \n",
            "scs                      2.1.2          \n",
            "seaborn                  0.10.0         \n",
            "semantic-version         2.8.4          \n",
            "Send2Trash               1.5.0          \n",
            "setuptools               46.1.3         \n",
            "setuptools-git           1.2            \n",
            "Shapely                  1.7.0          \n",
            "simplegeneric            0.8.1          \n",
            "six                      1.12.0         \n",
            "sklearn                  0.0            \n",
            "sklearn-pandas           1.8.0          \n",
            "smart-open               1.11.1         \n",
            "snowballstemmer          2.0.0          \n",
            "sortedcontainers         2.1.0          \n",
            "spacy                    2.2.4          \n",
            "Sphinx                   1.8.5          \n",
            "sphinxcontrib-websupport 1.2.1          \n",
            "SQLAlchemy               1.3.16         \n",
            "sqlparse                 0.3.1          \n",
            "srsly                    1.0.2          \n",
            "stable-baselines         2.2.1          \n",
            "statsmodels              0.10.2         \n",
            "sympy                    1.1.1          \n",
            "tables                   3.4.4          \n",
            "tabulate                 0.8.7          \n",
            "tbb                      2020.0.133     \n",
            "tblib                    1.6.0          \n",
            "tensor2tensor            1.14.1         \n",
            "tensorboard              1.15.0         \n",
            "tensorboard-plugin-wit   1.6.0.post3    \n",
            "tensorboardcolab         0.0.22         \n",
            "tensorflow               1.15.2         \n",
            "tensorflow-addons        0.8.3          \n",
            "tensorflow-datasets      2.1.0          \n",
            "tensorflow-estimator     1.15.1         \n",
            "tensorflow-gan           2.0.0          \n",
            "tensorflow-gcs-config    2.1.8          \n",
            "tensorflow-hub           0.8.0          \n",
            "tensorflow-metadata      0.21.2         \n",
            "tensorflow-privacy       0.2.2          \n",
            "tensorflow-probability   0.7.0          \n",
            "termcolor                1.1.0          \n",
            "terminado                0.8.3          \n",
            "testpath                 0.4.4          \n",
            "text-unidecode           1.3            \n",
            "textblob                 0.15.3         \n",
            "textgenrnn               1.4.1          \n",
            "tflearn                  0.3.2          \n",
            "Theano                   1.0.4          \n",
            "thinc                    7.4.0          \n",
            "toolz                    0.10.0         \n",
            "torch                    1.4.0          \n",
            "torchsummary             1.5.1          \n",
            "torchtext                0.3.1          \n",
            "torchvision              0.5.0          \n",
            "tornado                  4.5.3          \n",
            "tqdm                     4.38.0         \n",
            "traitlets                4.3.3          \n",
            "tweepy                   3.6.0          \n",
            "typeguard                2.7.1          \n",
            "typing                   3.6.6          \n",
            "typing-extensions        3.6.6          \n",
            "tzlocal                  1.5.1          \n",
            "umap-learn               0.4.1          \n",
            "uritemplate              3.0.1          \n",
            "urllib3                  1.24.3         \n",
            "vega-datasets            0.8.0          \n",
            "wasabi                   0.6.0          \n",
            "wcwidth                  0.1.9          \n",
            "webencodings             0.5.1          \n",
            "Werkzeug                 1.0.1          \n",
            "wheel                    0.34.2         \n",
            "widgetsnbextension       3.5.1          \n",
            "wordcloud                1.5.0          \n",
            "wrapt                    1.12.1         \n",
            "xarray                   0.15.1         \n",
            "xgboost                  0.90           \n",
            "xkit                     0.0.0          \n",
            "xlrd                     1.1.0          \n",
            "xlwt                     1.3.0          \n",
            "yellowbrick              0.9.1          \n",
            "zict                     2.0.0          \n",
            "zipp                     3.1.0          \n",
            "zmq                      0.0.0          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7sx1x00SzVE"
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWlyIOQ4S3yt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}